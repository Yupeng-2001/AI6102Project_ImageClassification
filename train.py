# -*- coding: utf-8 -*-
"""Copy of AI6102.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14P6VfChelYs1JyID4vQAQer5aBfQa-Ve

## data loading##

## Training of the model ##
parse parameters
"""

import datetime
import numpy as np
import torch
import copy
import random
import os
import pdb

from utils import save_model


def train_model(
    model,
    train_loader,
    val_loader,
    criterion,
    optimizer,
    model_save_path: str,
    model_type: str,
    scheduler=None,
    num_epochs=10,
    device="cuda",
):
    model.to(device)
    training_result = []
    best_model_params = copy.deepcopy(model.state_dict())
    best_valid_loss = 999999
    for epoch in range(num_epochs):
        cur_start = datetime.datetime.now()
        # Training phase
        model.train()
        running_loss = 0.0
        correct = 0
        # total = 1
        total = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)

            # train the model
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * images.size(0)
            if "ae" not in model_type:
                # saving loss and acc
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
            pass

        # update scheduler if not None
        if scheduler:
            scheduler.step()

        # calculate loss and accuracy
        train_loss = running_loss / len(train_loader.dataset)
        if "ae" not in model_type:
            train_acc = correct / total
        else:
            train_acc = 0
        print(f"Epoch : {epoch} \t-----------------")
        print(f"training time: {datetime.datetime.now() - cur_start}")
        print(f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}")
        print(f"\tcurrent LR: {scheduler.get_last_lr()[0]}")
        val_loss, val_acc = evaluate_model(
            model, model_type, val_loader, criterion, device
        )
        # val_loss = 5
        # val_acc = 0.5

        epoch_result = {}
        epoch_result["Epoch"] = epoch
        epoch_result["Train Loss"] = train_loss
        epoch_result["Train Acc"] = train_acc
        epoch_result["Val Loss"] = val_loss
        epoch_result["Val Acc"] = val_acc
        training_result.append(epoch_result)

        if val_loss < best_valid_loss:
            print(
                f">> better result achieved in epoch {epoch} with loss {val_loss} from prev {best_valid_loss}"
            )
            best_valid_loss = val_loss
            best_model_params = copy.deepcopy(model.state_dict())
            # save_model(
            #     model_save_path,
            #     model_type,
            #     training_result,
            #     best_valid_loss,
            #     model,
            #     train_loader.dataset.classes,
            # )
            os.makedirs(model_save_path, exist_ok=True)
            torch.save(
                model.state_dict(),
                os.path.join(model_save_path, f"model_ep{epoch}.pt"),
            )

    return training_result, (best_valid_loss, best_model_params)


def evaluate_model(model, model_type: str, val_loader, criterion, device="cuda"):
    model.eval()
    val_loss = 0.0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * images.size(0)
            if "ae" not in model_type:
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

    val_loss = val_loss / len(val_loader.dataset)
    if "ae" not in model_type:
        val_acc = correct / total
    else:
        val_acc = 0

    print(f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")
    return val_loss, val_acc
